#!/usr/bin/env python3
"""
Git Merge Helper - æ—¥å¿—æ¸…ç†å™¨

åŠŸèƒ½ï¼š
- è‡ªåŠ¨æ¸…ç†è¿‡æœŸçš„åˆå¹¶æ—¥å¿—
- ä¿ç•™ç­–ç•¥ï¼š
  * ä¸€å‘¨å†…æœ€å¤šä¿ç•™ 10 ä¸ªæ—¥å¿—
  * ä¸€ä¸ªæœˆå†…æœ€å¤šä¿ç•™ 5 ä¸ªæ—¥å¿—
  * è¶…è¿‡ä¸€ä¸ªæœˆçš„å…¨éƒ¨åˆ é™¤

æ”¯æŒå¤šç§æ—¥å¿—æ–‡ä»¶åæ ¼å¼ï¼š
  * merge-{source}-to-{target}-{timestamp}.log (æ–°æ ¼å¼)
  * merge-batch-{count}branches-{timestamp}.log (æ‰¹é‡åˆå¹¶)
  * merge_{timestamp}.log (æ—§æ ¼å¼)

Generated: 2026-01-04
"""

import os
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Tuple, Optional

# å¯¼å…¥ Git å·¥å…·ç±»
try:
    from git_utils import GitRepository
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œä½¿ç”¨å¤‡ç”¨å®ç°
    class GitRepository:
        DEFAULT_MAX_DEPTH = 50

        @staticmethod
        def find_root(start_dir=None, max_depth=None):
            if start_dir is None:
                start_dir = Path.cwd()
            if max_depth is None:
                max_depth = GitRepository.DEFAULT_MAX_DEPTH

            original_root = start_dir
            current = start_dir

            for _ in range(max_depth):
                if (current / ".git").exists():
                    return current
                if current.parent == current:
                    break
                current = current.parent

            raise RuntimeError(
                f"æœªæ‰¾åˆ° Git ä»“åº“ã€‚\n"
                f"èµ·å§‹ç›®å½•: {original_root}\n"
                f"æœ€å¤§æ·±åº¦: {max_depth}"
            )


class LogCleaner:
    """æ—¥å¿—æ¸…ç†å™¨"""

    # æ–°æ ¼å¼æ—¥å¿—æ–‡ä»¶å: merge-[source]-to-[target]-YYYYMMDD-HHMMSS.log
    # æ–°æ ¼å¼æ‰¹é‡: merge-batch-[count]branches-YYYYMMDD-HHMMSS.log
    # æ—§æ ¼å¼æ—¥å¿—æ–‡ä»¶å: merge_YYYYMMDD_HHMMSS.log
    LOG_PATTERNS = [
        # æ–°æ ¼å¼ï¼šmerge-[source]-to-[target]-20260104-143000.log
        re.compile(r'merge-\[([^\]]+)\]-to-\[([^\]]+)\]-(\d{8})-(\d{6})\.log'),
        # æ‰¹é‡æ ¼å¼ï¼šmerge-batch-[2branches]-20260104-143000.log
        re.compile(r'merge-batch-\[(\d+)branches\]-(\d{8})-(\d{6})\.log'),
        # æ—§æ ¼å¼ï¼šmerge_20260104_143000.log
        re.compile(r'merge_(\d{8})_(\d{6})\.log'),
    ]

    # æ¸…ç†ç­–ç•¥
    MAX_WEEK_LOGS = 10      # ä¸€å‘¨å†…æœ€å¤šä¿ç•™ 10 ä¸ª
    MAX_MONTH_LOGS = 5      # ä¸€ä¸ªæœˆå†…æœ€å¤šä¿ç•™ 5 ä¸ª
    WEEK_DAYS = 7           # ä¸€å‘¨å¤©æ•°
    MONTH_DAYS = 30         # ä¸€ä¸ªæœˆå¤©æ•°

    def __init__(self, logs_dir: Path):
        """
        åˆå§‹åŒ–æ—¥å¿—æ¸…ç†å™¨

        Args:
            logs_dir: æ—¥å¿—ç›®å½•è·¯å¾„
        """
        self.logs_dir = logs_dir
        self.cleaned_count = 0
        self.kept_count = 0

    def parse_log_file(self, filename: str) -> Tuple[Optional[datetime], str]:
        """
        è§£ææ—¥å¿—æ–‡ä»¶åï¼Œæå–æ—¶é—´æˆ³

        Args:
            filename: æ—¥å¿—æ–‡ä»¶å

        Returns:
            (æ—¶é—´æˆ³, å®Œæ•´æ–‡ä»¶è·¯å¾„) æˆ– (None, filename)
        """
        full_path = self.logs_dir / filename

        # å°è¯•åŒ¹é…æ‰€æœ‰æ—¥å¿—æ ¼å¼
        for pattern in self.LOG_PATTERNS:
            match = pattern.search(filename)
            if match:
                try:
                    # æ ¹æ®åŒ¹é…çš„ç»„æå–æ—¥æœŸå’Œæ—¶é—´
                    # æ—§æ ¼å¼å’Œæ–°æ ¼å¼çš„æ—¶é—´æˆ³ä½ç½®ä¸åŒ
                    groups = match.groups()
                    # æŸ¥æ‰¾æ—¥æœŸå’Œæ—¶é—´ç»„
                    date_str = None
                    time_str = None
                    for g in groups:
                        if g and len(g) == 8 and g.isdigit():  # æ—¥æœŸ YYYYMMDD
                            date_str = g
                        elif g and len(g) == 6 and g.isdigit():  # æ—¶é—´ HHMMSS
                            time_str = g

                    if date_str and time_str:
                        timestamp = datetime.strptime(f"{date_str}{time_str}", "%Y%m%d%H%M%S")
                        return timestamp, str(full_path)
                except (ValueError, IndexError):
                    continue

        return None, filename

    def get_all_logs(self) -> List[Tuple[datetime, str]]:
        """
        è·å–æ‰€æœ‰æœ‰æ•ˆçš„æ—¥å¿—æ–‡ä»¶ï¼ŒæŒ‰æ—¶é—´å€’åºæ’åˆ—

        Returns:
            [(æ—¶é—´æˆ³, æ–‡ä»¶è·¯å¾„), ...] åˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´å€’åº
        """
        if not self.logs_dir.exists():
            return []

        logs = []
        for filename in os.listdir(self.logs_dir):
            timestamp, full_path = self.parse_log_file(filename)
            if timestamp and Path(full_path).exists():
                logs.append((timestamp, full_path))

        # æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        logs.sort(key=lambda x: x[0], reverse=True)
        return logs

    def clean_logs(self, dry_run: bool = False) -> dict:
        """
        æ¸…ç†æ—¥å¿—æ–‡ä»¶

        Args:
            dry_run: æ˜¯å¦ä¸ºæ¼”ä¹ æ¨¡å¼ï¼ˆä¸å®é™…åˆ é™¤ï¼‰

        Returns:
            æ¸…ç†ç»“æœç»Ÿè®¡
        """
        logs = self.get_all_logs()
        now = datetime.now()

        # åˆ†ç±»æ—¥å¿—
        week_ago = now - timedelta(days=self.WEEK_DAYS)
        month_ago = now - timedelta(days=self.MONTH_DAYS)

        week_logs = [log for log in logs if log[0] > week_ago]
        month_logs = [log for log in logs if week_ago >= log[0] > month_ago]
        old_logs = [log for log in logs if log[0] <= month_ago]

        # ç¡®å®šè¦åˆ é™¤çš„æ–‡ä»¶
        to_delete = []

        # 1. ä¸€å‘¨å†…çš„æ—¥å¿—ï¼šåªä¿ç•™æœ€æ–°çš„ MAX_WEEK_LOGS ä¸ª
        if len(week_logs) > self.MAX_WEEK_LOGS:
            to_delete.extend(week_logs[self.MAX_WEEK_LOGS:])

        # 2. ä¸€ä¸ªæœˆå†…çš„æ—¥å¿—ï¼šåªä¿ç•™æœ€æ–°çš„ MAX_MONTH_LOGS ä¸ª
        if len(month_logs) > self.MAX_MONTH_LOGS:
            to_delete.extend(month_logs[self.MAX_MONTH_LOGS:])

        # 3. è¶…è¿‡ä¸€ä¸ªæœˆçš„æ—¥å¿—ï¼šå…¨éƒ¨åˆ é™¤
        to_delete.extend(old_logs)

        # å»é‡ï¼ˆæŒ‰æ–‡ä»¶è·¯å¾„ï¼‰
        to_delete_unique = []
        seen_paths = set()
        for log in to_delete:
            if log[1] not in seen_paths:
                to_delete_unique.append(log)
                seen_paths.add(log[1])

        # æ‰§è¡Œåˆ é™¤
        self.cleaned_count = 0
        self.kept_count = len(logs) - len(to_delete_unique)

        for timestamp, filepath in to_delete_unique:
            if dry_run:
                print(f"[æ¼”ä¹ ] å°†åˆ é™¤: {Path(filepath).name} ({timestamp.strftime('%Y-%m-%d %H:%M:%S')})")
            else:
                try:
                    os.remove(filepath)
                    self.cleaned_count += 1
                except Exception as e:
                    print(f"âš ï¸  åˆ é™¤å¤±è´¥: {filepath} - {str(e)}")

        return {
            "total_logs": len(logs),
            "week_logs": len(week_logs),
            "month_logs": len(month_logs),
            "old_logs": len(old_logs),
            "cleaned": self.cleaned_count,
            "kept": self.kept_count,
            "dry_run": dry_run
        }

    def get_cleanup_summary(self) -> str:
        """
        è·å–æ¸…ç†ç­–ç•¥è¯´æ˜

        Returns:
            æ¸…ç†ç­–ç•¥æ–‡æœ¬
        """
        return f"""
ğŸ“‹ æ—¥å¿—æ¸…ç†ç­–ç•¥
{'=' * 40}

ğŸ“Œ ä¿ç•™è§„åˆ™:
  â€¢ ä¸€å‘¨å†… (7å¤©): æœ€å¤šä¿ç•™ {self.MAX_WEEK_LOGS} ä¸ªæ—¥å¿—
  â€¢ ä¸€ä¸ªæœˆå†… (30å¤©): æœ€å¤šä¿ç•™ {self.MAX_MONTH_LOGS} ä¸ªæ—¥å¿—
  â€¢ è¶…è¿‡ä¸€ä¸ªæœˆ: å…¨éƒ¨åˆ é™¤

ğŸ“Š æ¸…ç†è¯´æ˜:
  â€¢ æ—¥å¿—æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼Œä¿ç•™æœ€æ–°çš„
  â€¢ è¶…å‡ºæ•°é‡é™åˆ¶çš„æ—§æ—¥å¿—å°†è¢«åˆ é™¤
  â€¢ æ¯æ¬¡åˆå¹¶åè‡ªåŠ¨æ‰§è¡Œæ¸…ç†

ğŸ“ æ—¥å¿—ä½ç½®: {self.logs_dir}

ğŸ’¡ æç¤º:
  â€¢ é‡è¦åˆå¹¶è®°å½•è¯·åŠæ—¶å¤‡ä»½
  â€¢ æ—¥å¿—æ–‡ä»¶åŒ…å«è¯¦ç»†çš„åˆå¹¶ä¿¡æ¯å’Œå†²çªæŠ¥å‘Š
"""


def clean_logs_after_merge(logs_dir: Path, verbose: bool = False) -> None:
    """
    åˆå¹¶åè‡ªåŠ¨æ¸…ç†æ—¥å¿—

    Args:
        logs_dir: æ—¥å¿—ç›®å½•
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    """
    cleaner = LogCleaner(logs_dir)

    # æ‰§è¡Œæ¸…ç†
    result = cleaner.clean_logs(dry_run=False)

    if verbose and result["cleaned"] > 0:
        print(f"\nğŸ§¹ å·²æ¸…ç† {result['cleaned']} ä¸ªæ—§æ—¥å¿—")
        print(f"ğŸ“Š ä¿ç•™ {result['kept']} ä¸ªæ—¥å¿—")


def main():
    """å‘½ä»¤è¡Œå…¥å£ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    import sys

    # è·å–æ—¥å¿—ç›®å½•
    if len(sys.argv) > 1:
        logs_dir = Path(sys.argv[1])
    else:
        # é»˜è®¤ä½¿ç”¨é¡¹ç›®ä¸­çš„ logs ç›®å½•
        try:
            project_root = GitRepository.find_root()
            logs_dir = project_root / ".claude" / "logs"
        except RuntimeError as e:
            print(f"âš ï¸  {e}")
            print(f"   å°†ä½¿ç”¨å½“å‰ç›®å½•çš„ .claude/logs/")
            logs_dir = Path.cwd() / ".claude" / "logs"

    cleaner = LogCleaner(logs_dir)

    # æ˜¾ç¤ºç­–ç•¥
    print(cleaner.get_cleanup_summary())

    # æ˜¾ç¤ºå½“å‰çŠ¶æ€
    logs = cleaner.get_all_logs()
    print(f"\nå½“å‰æ—¥å¿—æ•°: {len(logs)}")

    if logs:
        print("\næœ€è¿‘çš„æ—¥å¿—:")
        for i, (timestamp, filepath) in enumerate(logs[:5], 1):
            age = (datetime.now() - timestamp).days
            print(f"  {i}. {Path(filepath).name} ({age} å¤©å‰)")

    # è¯¢é—®æ˜¯å¦æ‰§è¡Œæ¸…ç†
    print("\n" + "-" * 40)
    response = input("æ˜¯å¦æ‰§è¡Œæ¸…ç†? (y/n): ").strip().lower()

    if response == 'y':
        # å…ˆæ¼”ä¹ 
        print("\næ¼”ä¹ æ¨¡å¼ (ä¸ä¼šå®é™…åˆ é™¤):")
        cleaner.clean_logs(dry_run=True)

        print("\n" + "-" * 40)
        response = input("ç¡®è®¤æ‰§è¡Œæ¸…ç†? (y/n): ").strip().lower()

        if response == 'y':
            result = cleaner.clean_logs(dry_run=False)
            print(f"\nâœ… æ¸…ç†å®Œæˆ!")
            print(f"   åˆ é™¤: {result['cleaned']} ä¸ª")
            print(f"   ä¿ç•™: {result['kept']} ä¸ª")
        else:
            print("å·²å–æ¶ˆæ¸…ç†")
    else:
        print("å·²å–æ¶ˆæ¸…ç†")


if __name__ == "__main__":
    main()
